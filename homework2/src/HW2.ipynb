{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Loading the data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update AWS Access Keys & Tokens as needed to retrieve data\n",
    "AWS_ACCESS_KEY_ID=\"ASIAYAAO5HRMNFMQ2YWL\"\n",
    "AWS_SECRET_ACCESS_KEY=\"GGKQ8l0zcgjvU4e15awGEebzxAnEY9JTTqQmH0LP\"\n",
    "AWS_SESSION_TOKEN=\"IQoJb3JpZ2luX2VjEMj//////////wEaCXVzLWVhc3QtMiJGMEQCIF84Rw9i5j2RDsFOilF6qFVyVOIUWDwN/Pbri3ODVb/vAiAM/oFwLmTlG1u/A0phIiGWqERo03gGVlqH+W8nTKQigCrrAggxEAAaDDU0OTc4NzA5MDAwOCIMVfzWCSIoBgUrrSKUKsgClegRWGtsjR7rJH+8fONraJQtxd2m1uXYpaC+pv92Cmo68UvJn2d4r1YipwFgCIuP7YADRPx432Bo1Psf3anKUixX0OzTUhLiil8D1Dgs+ceisDP5HvnQdk6uxKy/OIqDgfXFIcw1J9aa4fZ2Qb0dyuINwpnoqglJevUdhP4uWTWz9GuXAMOZnI483/v9OZTm1w5s3Ajs/gf5NvJI7P5lyrDujYPXcDxWSkb1ef3GeqGEb2FsC5cIdMpFl4WhyPhL2gVD/Ngc+sCyM/HXICf79194DG0lefbkm6/tQV91RM+91R04T7HPX/PnOMDivJ58x+GhT6UAMu+aEdaKEHnJSmIMr5YqT81efaCtpwHBYW4Zh2EgbFFjoEPYb+A1+mW6PcZQ09rzfOpFApwxZujL/LaQ2zKj6u0OHDZslI7ENKUzyKYNF23LFjDgkvmxBjqoAeeLgqLssNNIo/Tkbcgw2TxBL7CgtaV0S4BzbczFhGe2JHMxmR8YBedYaM33x+Uw8QDI1ADseBFHOExyMozkrLwStdok3Ii40fIfwCRbwJ0MP6m2RGM5UfTREeAyXlk192DT8ZSBJJ/ihsGwubcXSx+bkPvLf29WzW1DyI60TVYMS0qF91Ndua58EYzoBWIBen84RXOEj4SNp4TDiHd9Wc4+F/cENXYaHg==\"\n",
    "s3 = boto3.client('s3',\n",
    "                  aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                  aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "                  aws_session_token=AWS_SESSION_TOKEN)\n",
    "\n",
    "bucket_name = 'de300spring2024'\n",
    "object_key = 'ryan_newkirk/heart_disease.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_obj = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  age  sex  painloc  painexer  relrest  pncaden   cp  trestbps  htn   chol  \\\n",
      "0  63  1.0      NaN       NaN      NaN      NaN  1.0     145.0  1.0  233.0   \n",
      "1  67  1.0      NaN       NaN      NaN      NaN  4.0     160.0  1.0  286.0   \n",
      "2  67  1.0      NaN       NaN      NaN      NaN  4.0     120.0  1.0  229.0   \n",
      "3  37  1.0      NaN       NaN      NaN      NaN  3.0     130.0  0.0  250.0   \n",
      "4  41  0.0      NaN       NaN      NaN      NaN  2.0     130.0  1.0  204.0   \n",
      "\n",
      "   smoke  cigs  years  fbs  dm  famhist  restecg  ekgmo  ekgday(day  ekgyr  \\\n",
      "0    NaN  50.0   20.0  1.0 NaN      1.0      2.0    2.0         3.0   81.0   \n",
      "1    NaN  40.0   40.0  0.0 NaN      1.0      2.0    3.0         5.0   81.0   \n",
      "2    NaN  20.0   35.0  0.0 NaN      1.0      2.0    2.0        19.0   81.0   \n",
      "3    NaN   0.0    0.0  0.0 NaN      1.0      0.0    2.0        13.0   81.0   \n",
      "4    NaN   0.0    0.0  0.0 NaN      1.0      2.0    2.0         7.0   81.0   \n",
      "\n",
      "   dig  prop  nitr  pro  diuretic  proto  thaldur  thaltime   met  thalach  \\\n",
      "0  0.0   0.0   0.0  0.0       0.0    1.0     10.5       6.0  13.0    150.0   \n",
      "1  0.0   1.0   0.0  0.0       0.0    1.0      9.5       6.0  13.0    108.0   \n",
      "2  0.0   1.0   0.0  0.0       0.0    1.0      8.5       6.0  10.0    129.0   \n",
      "3  0.0   1.0   0.0  0.0       0.0    1.0     13.0      13.0  17.0    187.0   \n",
      "4  0.0   0.0   0.0  0.0       0.0    1.0      7.0       NaN   9.0    172.0   \n",
      "\n",
      "   thalrest  tpeakbps  tpeakbpd  dummy  trestbpd  exang  xhypo  oldpeak  \\\n",
      "0      60.0     190.0      90.0  145.0      85.0    0.0    0.0      2.3   \n",
      "1      64.0     160.0      90.0  160.0      90.0    1.0    0.0      1.5   \n",
      "2      78.0     140.0      80.0  120.0      80.0    1.0    0.0      2.6   \n",
      "3      84.0     195.0      68.0  130.0      78.0    0.0    0.0      3.5   \n",
      "4      71.0     160.0      74.0  130.0      86.0    0.0    0.0      1.4   \n",
      "\n",
      "   slope  rldv5  rldv5e   ca  restckm  exerckm  restef  restwm  exeref  \\\n",
      "0    3.0    NaN   172.0  0.0      NaN      NaN     NaN     NaN     NaN   \n",
      "1    2.0    NaN   185.0  3.0      NaN      NaN     NaN     NaN     NaN   \n",
      "2    2.0    NaN   150.0  2.0      NaN      NaN     NaN     NaN     NaN   \n",
      "3    3.0    NaN   167.0  0.0      NaN      NaN     NaN     NaN     NaN   \n",
      "4    1.0    NaN    40.0  0.0      NaN      NaN     NaN     NaN     NaN   \n",
      "\n",
      "   exerwm  thal  thalsev  thalpul  earlobe  cmo  cday   cyr  target  \n",
      "0     NaN   6.0      NaN      NaN      NaN  2.0  16.0  81.0     0.0  \n",
      "1     NaN   3.0      NaN      NaN      NaN  2.0   5.0  81.0     1.0  \n",
      "2     NaN   7.0      NaN      NaN      NaN  2.0  20.0  81.0     1.0  \n",
      "3     NaN   3.0      NaN      NaN      NaN  2.0   4.0  81.0     0.0  \n",
      "4     NaN   3.0      NaN      NaN      NaN  2.0  18.0  81.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(BytesIO(csv_string.encode()))\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1061, 56)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the cleaning steps\n",
    "\n",
    "Before the cleaning steps provided, because there are malformed rows of data that will make the rest of the process more complicated, I will remove any rows that have more than 90% of data missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 56)\n"
     ]
    }
   ],
   "source": [
    "# Define threshold for missing percentage\n",
    "threshold = 0.9\n",
    "\n",
    "# Remove rows\n",
    "df_clean = df[df.isnull().mean(axis=1) < threshold]\n",
    "\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retain only the following columns (apart from target):\n",
    "age, sex, painloc, painexer, cp, trestbps, smoke, fbs, prop, nitr, pro, diuretic, thaldur,\n",
    "thalach, exang, oldpeak, slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['painloc'].fillna(painloc_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['painloc'].fillna(painloc_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['painexer'].fillna(painexer_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['painexer'].fillna(painexer_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['trestbps'].fillna(trestbps_mean, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['trestbps'].fillna(trestbps_mean, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['oldpeak'].fillna(oldpeak_mean, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['oldpeak'].fillna(oldpeak_mean, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['thaldur'].fillna(painloc_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['thaldur'].fillna(painloc_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['thalach'].fillna(painexer_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['thalach'].fillna(painexer_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1[col].fillna(col_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['slope'].fillna(slope_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['slope'].fillna(slope_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_step1['cp'].fillna(slope_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['cp'].fillna(slope_mode, inplace=True)\n",
      "C:\\Users\\great\\AppData\\Local\\Temp\\ipykernel_27036\\3994128241.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_step1['age'] = pd.to_numeric(df_step1['age'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Define a list that contains the column names you want to keep\n",
    "cols_to_keep = ['age', 'sex', 'painloc', 'painexer', 'cp', 'trestbps', 'smoke', 'fbs', 'prop', \n",
    "                'nitr', 'pro', 'diuretic', 'thaldur', 'thalach', 'exang', 'oldpeak', 'slope', 'target']\n",
    "\n",
    "# Select only the columns of interest\n",
    "df_step1 = df_clean[cols_to_keep]\n",
    "# We can just keep the mode values for painloc and painexer, since these are binary values that would make the most sense for imputation\n",
    "painloc_mode = df_step1['painloc'].dropna().mode()[0]\n",
    "df_step1['painloc'].fillna(painloc_mode, inplace=True)\n",
    "painexer_mode = df_step1['painexer'].dropna().mode()[0]\n",
    "df_step1['painexer'].fillna(painexer_mode, inplace=True)\n",
    "\n",
    "# Calculate the mean for 'trestbps' column, to impute values less than 100 or null values\n",
    "trestbps_mean = df_step1['trestbps'][df_step1['trestbps'] >= 100].mean()\n",
    "df_step1.loc[df_step1['trestbps'] < 100, 'trestbps'] = trestbps_mean\n",
    "df_step1['trestbps'].fillna(trestbps_mean, inplace=True)\n",
    "#Do the same for oldpeak\n",
    "oldpeak_mean = df_step1['oldpeak'][(df_step1['oldpeak'] >= 0) & (df_step1['oldpeak'] <= 4)].mean()\n",
    "df_step1.loc[(df_step1['oldpeak'] < 0) | (df_step1['oldpeak'] > 4), 'oldpeak'] = oldpeak_mean\n",
    "df_step1['oldpeak'].fillna(oldpeak_mean, inplace=True)\n",
    "\n",
    "# impute with mean values for thaldur, thalach\n",
    "painloc_mode = df_step1['thaldur'].dropna().mean()\n",
    "df_step1['thaldur'].fillna(painloc_mode, inplace=True)\n",
    "painexer_mode = df_step1['thalach'].dropna().mean()\n",
    "df_step1['thalach'].fillna(painexer_mode, inplace=True)\n",
    "\n",
    "# fbs, prop, nitr, pro, diuretic: Replace the missing values and values greater than 1. This includes exang too as a binary variable\n",
    "binary_columns = ['fbs', 'prop', 'nitr', 'pro', 'diuretic', 'exang']\n",
    "for col in binary_columns:\n",
    "    col_mode = df_step1[col][df_step1[col] <= 1].mode()[0]\n",
    "    df_step1.loc[df_step1[col] > 1, col] = col_mode\n",
    "    df_step1[col].fillna(col_mode, inplace=True)\n",
    "\n",
    "# Since 'slope' and 'cp' are categorical data, we will impute using the mode\n",
    "slope_mode = df_step1['slope'].dropna().mode()[0]\n",
    "df_step1['slope'].fillna(slope_mode, inplace=True)\n",
    "slope_mode = df_step1['cp'].dropna().mode()[0]\n",
    "df_step1['cp'].fillna(slope_mode, inplace=True)\n",
    "\n",
    "df_step1['age'] = pd.to_numeric(df_step1['age'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to clean and impute the smoke column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_step2 = df_step1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_smoke: {1: 0.131, 0: 0.10099999999999999}\n",
      "age_smoke: {(18, 24): 0.053, (25, 44): 0.126, (45, 64): 0.149, (65, 1000): 0.083}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.cdc.gov/tobacco/data_statistics/fact_sheets/adult_data/cig_smoking/index.htm'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "ul_tags = soup.find_all('ul', {'class': 'block-list'})\n",
    "gender_smoke_data = ul_tags[1].find_all('li') \n",
    "age_smoke_data = ul_tags[2].find_all('li')\n",
    "\n",
    "def extract_percentage(text):\n",
    "    start = text.find('(') + 1  \n",
    "    end = text.find('%)') \n",
    "    return float(text[start:end])/100  \n",
    "\n",
    "gender_smoke = {\n",
    "    1: extract_percentage(gender_smoke_data[0].text),\n",
    "    0: extract_percentage(gender_smoke_data[1].text)\n",
    "}\n",
    "age_brackets = {\n",
    "    '18–24 years': [18,24],\n",
    "    '25–44 years': [25,44],\n",
    "    '45–64 years': [45,64],\n",
    "    '65 years and older': [65, 1000]\n",
    "}\n",
    "\n",
    "age_smoke = {}\n",
    "for li in age_smoke_data:\n",
    "    for bracket_key, bracket_range in age_brackets.items():\n",
    "        if bracket_key in li.text:\n",
    "            age_smoke[tuple(bracket_range)] = extract_percentage(li.text)\n",
    "\n",
    "print(\"gender_smoke:\", gender_smoke)\n",
    "print(\"age_smoke:\", age_smoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(15, 17): 0.016, (18, 24): 0.073, (25, 34): 0.109, (35, 44): 0.109, (45, 54): 0.138, (55, 64): 0.149, (65, 74): 0.087, (75, 1000): 0.028999999999999998}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.abs.gov.au/statistics/health/health-conditions-and-risks/smoking/latest-release'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "chart_data = None\n",
    "for d in soup.find_all('div', {'class': 'chart-data-wrapper'}):\n",
    "    c = d.find('pre', {'class': 'chart-caption'}).text\n",
    "    if \"Proportion of people 15 years and over who were current daily smokers by age, 2011–12 to 2022\" in c:\n",
    "        chart_data = json.loads(d.find('pre', {'class': 'chart-data'}).text)\n",
    "        break\n",
    "\n",
    "age_ranges = [(15, 17), (18, 24), (25, 34), (35, 44), (45, 54), (55, 64), (65, 74), (75, 1000)]\n",
    "smoking_values = np.divide(np.ravel(chart_data[7]), 100)\n",
    "smoke_dict = {age_range: smoking_rate for age_range, smoking_rate in zip(age_ranges, smoking_values)}\n",
    "\n",
    "print(smoke_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [15, 18, 25, 35, 45, 55, 65, 75, float('inf')]\n",
    "age_labels = [(15, 17), (18, 24), (25, 34), (35, 44), (45, 54), (55, 64), (65, 74), (75, 1000)]\n",
    "missing_age_counts = {}\n",
    "\n",
    "missing_smoke = df_step2[df_step2['smoke'].isna()]\n",
    "\n",
    "for i in range(len(age_bins) - 1):\n",
    "    if i == 0:\n",
    "        mask = missing_smoke['age'].between(age_bins[i], age_bins[i+1], inclusive=\"right\")\n",
    "    else:\n",
    "        mask = missing_smoke['age'].between(age_bins[i], age_bins[i+1], inclusive=\"left\")\n",
    "    missing_age_counts[age_labels[i]] = missing_smoke[mask].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the age groups are more precice from abs.gov.au but we have gender statistics from cdc.gov, so we will combine those two together in order to impute smoke data.\n",
    "\n",
    "Since Source 1 and Source 2's age groups kind of conflict with each other, I will just stick to using Source 1's age groups and use Source 2's gender statistics. Then, I will replace missing values for all female pations just according to the smoking rate in the corresponding age groups, while using the provided calculation \"smoking rate in age group * smoking rage among men / smoking rate among women\" to determine the percentage of smoking and nonsmoking men there are.\n",
    "\n",
    "From there, I will see how many null values for each gender are in each age group, and then distribute the amount of 0's and 1's accordingly and randomly to match the percentages from the sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_dict_men = {\n",
    "    age_range: rate * gender_smoke[1] / gender_smoke[0] for age_range, rate in smoke_dict.items()\n",
    "}\n",
    "\n",
    "def calc_smoke_values(missing_count, smoker_probability):\n",
    "    num_smokers = round(missing_count * smoker_probability)\n",
    "    num_non_smokers = missing_count - num_smokers\n",
    "    smoke_values = ([1] * num_smokers) + ([0] * num_non_smokers)\n",
    "    np.random.shuffle(smoke_values)\n",
    "    return smoke_values\n",
    "\n",
    "for gender in [0, 1]: \n",
    "    current_smoke_dict = smoke_dict_men if gender == 1 else smoke_dict\n",
    "    \n",
    "    for age_range in current_smoke_dict.keys():\n",
    "        smoker_probability = current_smoke_dict[age_range]\n",
    "\n",
    "        mask_age_gender = (\n",
    "            df_step2['smoke'].isna() & \n",
    "            (df_step2['age'] >= age_range[0]) & \n",
    "            (df_step2['age'] <= age_range[1]) & \n",
    "            (df_step2['sex'] == gender)\n",
    "        )\n",
    "        missing_count = mask_age_gender.sum()\n",
    "\n",
    "        num_smokers = round(missing_count * smoker_probability)\n",
    "        num_non_smokers = missing_count - num_smokers\n",
    "\n",
    "        smoke_values = ([1] * num_smokers) + ([0] * num_non_smokers)\n",
    "\n",
    "        indices_to_impute = df_step2.loc[mask_age_gender].index  \n",
    "\n",
    "        if len(indices_to_impute) > 0:\n",
    "            np.random.shuffle(smoke_values)\n",
    "\n",
    "            df_step2.loc[indices_to_impute, 'smoke'] = smoke_values[:len(indices_to_impute)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_step3 = df_step2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Split the data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_step3.drop(columns='target')\n",
    "y = df_step3['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.1,        \n",
    "    stratify=y,           # stratifies the split according to the labels in y\n",
    "    random_state=42       \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Train a few binary classification models on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = {\n",
    "    'Random Forest': {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [100, 300, 500],\n",
    "        'classifier__max_depth': [5, 10, None]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'classifier': [LogisticRegression(class_weight='balanced', max_iter=2000)],\n",
    "        'classifier__C': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [None, 2, 5, 10],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'classifier': [GradientBoostingClassifier()],\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1],\n",
    "        'classifier__max_depth': [3, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, params in param_grid.items():\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('classifier', None)\n",
    "    ])\n",
    "    search = GridSearchCV(\n",
    "        pipe, \n",
    "        params, \n",
    "        scoring={'accuracy': make_scorer(accuracy_score),\n",
    "                'precision': make_scorer(precision_score),\n",
    "                'recall': make_scorer(recall_score),\n",
    "                'f1_score': make_scorer(f1_score)}, \n",
    "        refit='f1_score', \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    results[model_name] = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.790 (+/- 0.090)\n",
      "Precision: 0.796 (+/- 0.077)\n",
      "Recall: 0.789 (+/- 0.084)\n",
      "F1 score: 0.789 (+/- 0.091)\n",
      "\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.786 (+/- 0.056)\n",
      "Precision: 0.792 (+/- 0.062)\n",
      "Recall: 0.786 (+/- 0.056)\n",
      "F1 score: 0.786 (+/- 0.059)\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.753 (+/- 0.054)\n",
      "Precision: 0.761 (+/- 0.037)\n",
      "Recall: 0.755 (+/- 0.047)\n",
      "F1 score: 0.752 (+/- 0.056)\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.753 (+/- 0.067)\n",
      "Precision: 0.759 (+/- 0.072)\n",
      "Recall: 0.755 (+/- 0.073)\n",
      "F1 score: 0.751 (+/- 0.083)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for model_name in results:\n",
    "    clf = results[model_name]\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    accuracy_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    print(f\"Accuracy: {accuracy_scores.mean():.3f} (+/- {accuracy_scores.std() * 2:.3f})\")\n",
    "\n",
    "    precision_scores = cross_val_score(clf, X, y, cv=cv, scoring='precision_weighted')\n",
    "    print(f\"Precision: {precision_scores.mean():.3f} (+/- {precision_scores.std() * 2:.3f})\")\n",
    "\n",
    "    recall_scores = cross_val_score(clf, X, y, cv=cv, scoring='recall_weighted')\n",
    "    print(f\"Recall: {recall_scores.mean():.3f} (+/- {recall_scores.std() * 2:.3f})\")\n",
    "    \n",
    "    f1_scores = cross_val_score(clf, X, y, cv=cv, scoring='f1_weighted')\n",
    "    print(f\"F1 score: {f1_scores.mean():.3f} (+/- {f1_scores.std() * 2:.3f})\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Select your final model based on relevant criteria.\n",
    "I think Random Forest is the best choice here. The Random Forest has the highest accuracy, precision, recall, and F1 score, which are all very important criteria in choosing an accurate predictor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
